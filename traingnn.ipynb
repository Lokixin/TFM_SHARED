{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Projects/TFM/dataset/AD_MCI_HC_WINDOWED\"\n",
    "INDEX_PATH = \"C:/Projects/TFM/dataset/AD_MCI_HC_WINDOWED/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphBuilder.graphbuilder import RawAndPearson, MomentsAndPearson\n",
    "from GraphBuilder.data_reader import read_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, indices ,builder, transform=None, target_transform=None):\n",
    "        self.indices = indices\n",
    "        self.builder = builder\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_path = self.indices.iloc[idx][\"path\"]\n",
    "        raw_data = read_record(current_path)\n",
    "        label = self.indices.iloc[idx][\"label\"]\n",
    "        data = self.builder.build(raw_data, label)\n",
    "        \n",
    "        return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = pd.read_csv(INDEX_PATH, index_col=\"Unnamed: 0\")\n",
    "indices = indices.drop(indices[indices.label == \"MCI\"].index)\n",
    "train_data, test_data = train_test_split(indices)\n",
    "\n",
    "#builder = RawAndPearson()\n",
    "builder = MomentsAndPearson()\n",
    "\n",
    "train_dataset = BaseDataset(train_data, builder)\n",
    "test_dataset = BaseDataset(test_data, builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.4413,  0.4517,  0.1795, -0.3905, -0.2489,  0.1070,  0.2346,\n",
      "          0.0000, -0.3596, -0.3325,  0.0000,  0.1260,  0.0000, -0.2600, -0.2011,\n",
      "          0.0000,  0.0000, -0.1146],\n",
      "        [ 0.4413,  1.0000,  0.2428,  0.0000, -0.3901,  0.1542,  0.4326,  0.1719,\n",
      "         -0.1306, -0.3529, -0.1497,  0.1987,  0.0000, -0.1251, -0.2230, -0.1410,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4517,  0.2428,  1.0000,  0.4259, -0.2062,  0.0000,  0.4708,  0.7354,\n",
      "          0.4779,  0.0000,  0.0000,  0.3562,  0.5565,  0.2621,  0.0000,  0.1164,\n",
      "          0.2498,  0.2275,  0.1620],\n",
      "        [ 0.1795,  0.0000,  0.4259,  1.0000,  0.2494,  0.0000,  0.0000,  0.2321,\n",
      "          0.5620,  0.1238, -0.1272, -0.1096,  0.1771,  0.1635,  0.0000, -0.1035,\n",
      "         -0.1030,  0.0000, -0.1364],\n",
      "        [-0.3905, -0.3901, -0.2062,  0.2494,  1.0000,  0.3488, -0.1455, -0.2137,\n",
      "          0.3471,  0.6368,  0.3409, -0.2127, -0.1002,  0.1723,  0.2310,  0.1275,\n",
      "         -0.1523,  0.0000,  0.0000],\n",
      "        [-0.2489,  0.1542,  0.0000,  0.0000,  0.3488,  1.0000,  0.4219,  0.0000,\n",
      "          0.0000,  0.3216,  0.5352,  0.3060,  0.0000,  0.0000,  0.1402,  0.2260,\n",
      "          0.1024,  0.0000,  0.0000],\n",
      "        [ 0.1070,  0.4326,  0.4708,  0.0000, -0.1455,  0.4219,  1.0000,  0.4420,\n",
      "          0.1840,  0.0000,  0.3799,  0.6903,  0.3783,  0.1326,  0.1373,  0.3189,\n",
      "          0.4736,  0.2182,  0.3370],\n",
      "        [ 0.2346,  0.1719,  0.7354,  0.2321, -0.2137,  0.0000,  0.4420,  1.0000,\n",
      "          0.4821,  0.0000,  0.1530,  0.4128,  0.7475,  0.4615,  0.2197,  0.2217,\n",
      "          0.2662,  0.3921,  0.2702],\n",
      "        [ 0.0000, -0.1306,  0.4779,  0.5620,  0.3471,  0.0000,  0.1840,  0.4821,\n",
      "          1.0000,  0.5668,  0.2995,  0.1826,  0.5804,  0.6752,  0.4654,  0.3253,\n",
      "          0.1497,  0.3900,  0.1957],\n",
      "        [-0.3596, -0.3529,  0.0000,  0.1238,  0.6368,  0.3216,  0.0000,  0.0000,\n",
      "          0.5668,  1.0000,  0.7135,  0.1477,  0.2979,  0.6691,  0.7643,  0.6224,\n",
      "          0.1906,  0.4166,  0.3522],\n",
      "        [-0.3325, -0.1497,  0.0000, -0.1272,  0.3409,  0.5352,  0.3799,  0.1530,\n",
      "          0.2995,  0.7135,  1.0000,  0.5800,  0.2872,  0.5022,  0.7092,  0.8337,\n",
      "          0.5330,  0.4224,  0.5349],\n",
      "        [ 0.0000,  0.1987,  0.3562, -0.1096, -0.2127,  0.3060,  0.6903,  0.4128,\n",
      "          0.1826,  0.1477,  0.5800,  1.0000,  0.4321,  0.2899,  0.3871,  0.6833,\n",
      "          0.8821,  0.3680,  0.6116],\n",
      "        [ 0.1260,  0.0000,  0.5565,  0.1771, -0.1002,  0.0000,  0.3783,  0.7475,\n",
      "          0.5804,  0.2979,  0.2872,  0.4321,  1.0000,  0.7466,  0.5387,  0.4091,\n",
      "          0.3287,  0.7601,  0.4717],\n",
      "        [ 0.0000, -0.1251,  0.2621,  0.1635,  0.1723,  0.0000,  0.1326,  0.4615,\n",
      "          0.6752,  0.6691,  0.5022,  0.2899,  0.7466,  1.0000,  0.8553,  0.6049,\n",
      "          0.2977,  0.8230,  0.5362],\n",
      "        [-0.2600, -0.2230,  0.0000,  0.0000,  0.2310,  0.1402,  0.1373,  0.2197,\n",
      "          0.4654,  0.7643,  0.7092,  0.3871,  0.5387,  0.8553,  1.0000,  0.8451,\n",
      "          0.4736,  0.7942,  0.7387],\n",
      "        [-0.2011, -0.1410,  0.1164, -0.1035,  0.1275,  0.2260,  0.3189,  0.2217,\n",
      "          0.3253,  0.6224,  0.8337,  0.6833,  0.4091,  0.6049,  0.8451,  1.0000,\n",
      "          0.7850,  0.5814,  0.7898],\n",
      "        [ 0.0000,  0.0000,  0.2498, -0.1030, -0.1523,  0.1024,  0.4736,  0.2662,\n",
      "          0.1497,  0.1906,  0.5330,  0.8821,  0.3287,  0.2977,  0.4736,  0.7850,\n",
      "          1.0000,  0.3712,  0.7428],\n",
      "        [ 0.0000,  0.0000,  0.2275,  0.0000,  0.0000,  0.0000,  0.2182,  0.3921,\n",
      "          0.3900,  0.4166,  0.4224,  0.3680,  0.7601,  0.8230,  0.7942,  0.5814,\n",
      "          0.3712,  1.0000,  0.7224],\n",
      "        [-0.1146,  0.0000,  0.1620, -0.1364,  0.0000,  0.0000,  0.3370,  0.2702,\n",
      "          0.1957,  0.3522,  0.5349,  0.6116,  0.4717,  0.5362,  0.7387,  0.7898,\n",
      "          0.7428,  0.7224,  1.0000]], dtype=torch.float64)\n",
      "torch.Size([19, 6])\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    print(data[0].edge_attr)\n",
    "    print(next(iter(data[0]))[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm, global_add_pool\n",
    "\n",
    "\n",
    "class EEGGNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduced_sensors, sfreq=None, batch_size=32):\n",
    "        super(EEGGNN, self).__init__()\n",
    "        # Define and initialize hyperparameters\n",
    "        self.sfreq = sfreq\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = 8 if reduced_sensors else 62\n",
    "        \n",
    "        # Layers definition\n",
    "        # Graph convolutional layers\n",
    "        self.conv1 = GCNConv(6, 16, cached=True, normalize=False)\n",
    "        self.conv2 = GCNConv(16, 32, cached=True, normalize=False)\n",
    "        self.conv3 = GCNConv(32, 64, cached=True, normalize=False)\n",
    "        self.conv4 = GCNConv(64, 50, cached=True, normalize=False)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norm = BatchNorm(50)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(50, 30)\n",
    "        self.fc2 = nn.Linear(30, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "        # Xavier initializacion for fully connected layers\n",
    "        self.fc1.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "        self.fc2.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "        self.fc3.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weigth, batch):\n",
    "        # Perform all graph convolutions\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index, edge_weigth))\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index, edge_weigth))\n",
    "        x = F.leaky_relu(self.conv3(x, edge_index, edge_weigth))\n",
    "        conv_out = F.leaky_relu(self.conv4(x, edge_index, edge_weigth))\n",
    "        \n",
    "        # Perform batch normalization\n",
    "        batch_norm_out = F.leaky_relu(self.batch_norm(conv_out))\n",
    "        \n",
    "        # Global add pooling\n",
    "        mean_pool = global_add_pool(batch_norm_out, batch=batch)\n",
    "        \n",
    "        # Apply fully connected layters\n",
    "        out = F.leaky_relu(self.fc1(mean_pool), negative_slope=0.01)\n",
    "        out = F.dropout(out, p = 0.2, training=self.training)\n",
    "        out = F.leaky_relu(self.fc2(out), negative_slope=0.01)\n",
    "        out = F.leaky_relu(self.fc3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.019\n",
      "Epoch: 000, Train Acc: 0.6982, Test Acc: 0.7093\n",
      "[2,     1] loss: 0.013\n",
      "Epoch: 001, Train Acc: 0.7173, Test Acc: 0.7275\n",
      "[3,     1] loss: 0.012\n",
      "Epoch: 002, Train Acc: 0.7057, Test Acc: 0.7150\n",
      "[4,     1] loss: 0.012\n",
      "Epoch: 003, Train Acc: 0.7172, Test Acc: 0.7323\n",
      "[5,     1] loss: 0.011\n",
      "Epoch: 004, Train Acc: 0.7169, Test Acc: 0.7306\n",
      "[6,     1] loss: 0.011\n",
      "Epoch: 005, Train Acc: 0.7185, Test Acc: 0.7323\n",
      "[7,     1] loss: 0.012\n",
      "Epoch: 006, Train Acc: 0.7150, Test Acc: 0.7275\n",
      "[8,     1] loss: 0.011\n",
      "Epoch: 007, Train Acc: 0.7183, Test Acc: 0.7345\n",
      "[9,     1] loss: 0.012\n",
      "Epoch: 008, Train Acc: 0.7190, Test Acc: 0.7319\n",
      "[10,     1] loss: 0.012\n",
      "Epoch: 009, Train Acc: 0.7190, Test Acc: 0.7319\n",
      "[11,     1] loss: 0.012\n",
      "Epoch: 010, Train Acc: 0.7192, Test Acc: 0.7319\n",
      "[12,     1] loss: 0.012\n",
      "Epoch: 011, Train Acc: 0.7190, Test Acc: 0.7323\n",
      "[13,     1] loss: 0.012\n",
      "Epoch: 012, Train Acc: 0.7203, Test Acc: 0.7328\n",
      "[14,     1] loss: 0.012\n",
      "Epoch: 013, Train Acc: 0.7154, Test Acc: 0.7275\n",
      "[15,     1] loss: 0.011\n",
      "Epoch: 014, Train Acc: 0.7190, Test Acc: 0.7336\n",
      "[16,     1] loss: 0.013\n",
      "Epoch: 015, Train Acc: 0.7196, Test Acc: 0.7354\n",
      "[17,     1] loss: 0.012\n",
      "Epoch: 016, Train Acc: 0.7205, Test Acc: 0.7345\n",
      "[18,     1] loss: 0.012\n",
      "Epoch: 017, Train Acc: 0.7134, Test Acc: 0.7262\n",
      "[19,     1] loss: 0.012\n",
      "Epoch: 018, Train Acc: 0.7190, Test Acc: 0.7336\n",
      "[20,     1] loss: 0.012\n",
      "Epoch: 019, Train Acc: 0.7193, Test Acc: 0.7306\n",
      "[21,     1] loss: 0.012\n",
      "Epoch: 020, Train Acc: 0.6930, Test Acc: 0.6989\n",
      "[22,     1] loss: 0.012\n",
      "Epoch: 021, Train Acc: 0.7089, Test Acc: 0.7189\n",
      "[23,     1] loss: 0.013\n",
      "Epoch: 022, Train Acc: 0.7180, Test Acc: 0.7284\n",
      "[24,     1] loss: 0.012\n",
      "Epoch: 023, Train Acc: 0.7190, Test Acc: 0.7310\n",
      "[25,     1] loss: 0.013\n",
      "Epoch: 024, Train Acc: 0.7198, Test Acc: 0.7328\n",
      "[26,     1] loss: 0.012\n",
      "Epoch: 025, Train Acc: 0.7198, Test Acc: 0.7328\n",
      "[27,     1] loss: 0.012\n",
      "Epoch: 026, Train Acc: 0.7193, Test Acc: 0.7341\n",
      "[28,     1] loss: 0.012\n",
      "Epoch: 027, Train Acc: 0.7198, Test Acc: 0.7323\n",
      "[29,     1] loss: 0.011\n",
      "Epoch: 028, Train Acc: 0.7193, Test Acc: 0.7336\n",
      "[30,     1] loss: 0.012\n",
      "Epoch: 029, Train Acc: 0.7196, Test Acc: 0.7323\n",
      "[31,     1] loss: 0.012\n",
      "Epoch: 030, Train Acc: 0.7205, Test Acc: 0.7341\n",
      "[32,     1] loss: 0.012\n",
      "Epoch: 031, Train Acc: 0.7199, Test Acc: 0.7332\n",
      "[33,     1] loss: 0.012\n",
      "Epoch: 032, Train Acc: 0.7201, Test Acc: 0.7332\n",
      "[34,     1] loss: 0.011\n",
      "Epoch: 033, Train Acc: 0.7195, Test Acc: 0.7336\n",
      "[35,     1] loss: 0.011\n",
      "Epoch: 034, Train Acc: 0.7196, Test Acc: 0.7336\n",
      "[36,     1] loss: 0.012\n",
      "Epoch: 035, Train Acc: 0.7211, Test Acc: 0.7349\n",
      "[37,     1] loss: 0.011\n",
      "Epoch: 036, Train Acc: 0.7212, Test Acc: 0.7349\n",
      "[38,     1] loss: 0.010\n",
      "Epoch: 037, Train Acc: 0.7211, Test Acc: 0.7345\n",
      "[39,     1] loss: 0.013\n",
      "Epoch: 038, Train Acc: 0.7192, Test Acc: 0.7354\n",
      "[40,     1] loss: 0.011\n",
      "Epoch: 039, Train Acc: 0.7202, Test Acc: 0.7341\n",
      "[41,     1] loss: 0.011\n",
      "Epoch: 040, Train Acc: 0.7211, Test Acc: 0.7349\n",
      "[42,     1] loss: 0.011\n",
      "Epoch: 041, Train Acc: 0.7211, Test Acc: 0.7345\n",
      "[43,     1] loss: 0.012\n",
      "Epoch: 042, Train Acc: 0.7201, Test Acc: 0.7354\n",
      "[44,     1] loss: 0.011\n",
      "Epoch: 043, Train Acc: 0.7202, Test Acc: 0.7354\n",
      "[45,     1] loss: 0.013\n",
      "Epoch: 044, Train Acc: 0.7206, Test Acc: 0.7358\n",
      "[46,     1] loss: 0.011\n",
      "Epoch: 045, Train Acc: 0.7205, Test Acc: 0.7354\n",
      "[47,     1] loss: 0.012\n",
      "Epoch: 046, Train Acc: 0.7208, Test Acc: 0.7349\n",
      "[48,     1] loss: 0.011\n",
      "Epoch: 047, Train Acc: 0.7209, Test Acc: 0.7354\n",
      "[49,     1] loss: 0.011\n",
      "Epoch: 048, Train Acc: 0.7198, Test Acc: 0.7362\n",
      "[50,     1] loss: 0.012\n",
      "Epoch: 049, Train Acc: 0.7206, Test Acc: 0.7362\n",
      "[51,     1] loss: 0.012\n",
      "Epoch: 050, Train Acc: 0.7209, Test Acc: 0.7375\n",
      "[52,     1] loss: 0.011\n",
      "Epoch: 051, Train Acc: 0.7215, Test Acc: 0.7367\n",
      "[53,     1] loss: 0.012\n",
      "Epoch: 052, Train Acc: 0.7221, Test Acc: 0.7371\n",
      "[54,     1] loss: 0.012\n",
      "Epoch: 053, Train Acc: 0.7218, Test Acc: 0.7358\n",
      "[55,     1] loss: 0.011\n",
      "Epoch: 054, Train Acc: 0.7219, Test Acc: 0.7371\n",
      "[56,     1] loss: 0.011\n",
      "Epoch: 055, Train Acc: 0.7221, Test Acc: 0.7375\n",
      "[57,     1] loss: 0.012\n",
      "Epoch: 056, Train Acc: 0.7219, Test Acc: 0.7371\n",
      "[58,     1] loss: 0.012\n",
      "Epoch: 057, Train Acc: 0.7219, Test Acc: 0.7371\n",
      "[59,     1] loss: 0.012\n",
      "Epoch: 058, Train Acc: 0.7209, Test Acc: 0.7375\n",
      "[60,     1] loss: 0.012\n",
      "Epoch: 059, Train Acc: 0.7214, Test Acc: 0.7375\n",
      "[61,     1] loss: 0.012\n",
      "Epoch: 060, Train Acc: 0.7219, Test Acc: 0.7380\n",
      "[62,     1] loss: 0.010\n",
      "Epoch: 061, Train Acc: 0.7216, Test Acc: 0.7375\n",
      "[63,     1] loss: 0.012\n",
      "Epoch: 062, Train Acc: 0.7222, Test Acc: 0.7375\n",
      "[64,     1] loss: 0.012\n",
      "Epoch: 063, Train Acc: 0.7221, Test Acc: 0.7375\n",
      "[65,     1] loss: 0.011\n",
      "Epoch: 064, Train Acc: 0.7221, Test Acc: 0.7375\n",
      "[66,     1] loss: 0.012\n",
      "Epoch: 065, Train Acc: 0.7222, Test Acc: 0.7362\n",
      "[67,     1] loss: 0.011\n",
      "Epoch: 066, Train Acc: 0.7221, Test Acc: 0.7380\n",
      "[68,     1] loss: 0.012\n",
      "Epoch: 067, Train Acc: 0.7216, Test Acc: 0.7367\n",
      "[69,     1] loss: 0.011\n",
      "Epoch: 068, Train Acc: 0.7224, Test Acc: 0.7375\n",
      "[70,     1] loss: 0.011\n",
      "Epoch: 069, Train Acc: 0.7222, Test Acc: 0.7380\n",
      "[71,     1] loss: 0.011\n",
      "Epoch: 070, Train Acc: 0.7219, Test Acc: 0.7380\n",
      "[72,     1] loss: 0.011\n",
      "Epoch: 071, Train Acc: 0.7216, Test Acc: 0.7380\n",
      "[73,     1] loss: 0.011\n",
      "Epoch: 072, Train Acc: 0.7221, Test Acc: 0.7380\n",
      "[74,     1] loss: 0.011\n",
      "Epoch: 073, Train Acc: 0.7224, Test Acc: 0.7375\n",
      "[75,     1] loss: 0.012\n",
      "Epoch: 074, Train Acc: 0.7222, Test Acc: 0.7375\n",
      "[76,     1] loss: 0.011\n",
      "Epoch: 075, Train Acc: 0.7224, Test Acc: 0.7380\n",
      "[77,     1] loss: 0.012\n",
      "Epoch: 076, Train Acc: 0.7222, Test Acc: 0.7371\n",
      "[78,     1] loss: 0.011\n",
      "Epoch: 077, Train Acc: 0.7219, Test Acc: 0.7380\n",
      "[79,     1] loss: 0.011\n",
      "Epoch: 078, Train Acc: 0.7225, Test Acc: 0.7375\n",
      "[80,     1] loss: 0.012\n",
      "Epoch: 079, Train Acc: 0.7224, Test Acc: 0.7362\n",
      "[81,     1] loss: 0.012\n",
      "Epoch: 080, Train Acc: 0.7225, Test Acc: 0.7375\n",
      "[82,     1] loss: 0.012\n",
      "Epoch: 081, Train Acc: 0.7224, Test Acc: 0.7367\n",
      "[83,     1] loss: 0.012\n",
      "Epoch: 082, Train Acc: 0.7228, Test Acc: 0.7375\n",
      "[84,     1] loss: 0.011\n",
      "Epoch: 083, Train Acc: 0.7225, Test Acc: 0.7371\n",
      "[85,     1] loss: 0.012\n",
      "Epoch: 084, Train Acc: 0.7225, Test Acc: 0.7367\n",
      "[86,     1] loss: 0.012\n",
      "Epoch: 085, Train Acc: 0.7225, Test Acc: 0.7375\n",
      "[87,     1] loss: 0.012\n",
      "Epoch: 086, Train Acc: 0.7225, Test Acc: 0.7371\n",
      "[88,     1] loss: 0.012\n",
      "Epoch: 087, Train Acc: 0.7225, Test Acc: 0.7367\n",
      "[89,     1] loss: 0.011\n",
      "Epoch: 088, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[90,     1] loss: 0.011\n",
      "Epoch: 089, Train Acc: 0.7225, Test Acc: 0.7367\n",
      "[91,     1] loss: 0.011\n",
      "Epoch: 090, Train Acc: 0.7225, Test Acc: 0.7371\n",
      "[92,     1] loss: 0.012\n",
      "Epoch: 091, Train Acc: 0.7227, Test Acc: 0.7380\n",
      "[93,     1] loss: 0.012\n",
      "Epoch: 092, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[94,     1] loss: 0.011\n",
      "Epoch: 093, Train Acc: 0.7219, Test Acc: 0.7380\n",
      "[95,     1] loss: 0.012\n",
      "Epoch: 094, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[96,     1] loss: 0.011\n",
      "Epoch: 095, Train Acc: 0.7221, Test Acc: 0.7375\n",
      "[97,     1] loss: 0.011\n",
      "Epoch: 096, Train Acc: 0.7222, Test Acc: 0.7380\n",
      "[98,     1] loss: 0.012\n",
      "Epoch: 097, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[99,     1] loss: 0.012\n",
      "Epoch: 098, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[100,     1] loss: 0.012\n",
      "Epoch: 099, Train Acc: 0.7228, Test Acc: 0.7375\n",
      "[101,     1] loss: 0.012\n",
      "Epoch: 100, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[102,     1] loss: 0.011\n",
      "Epoch: 101, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[103,     1] loss: 0.011\n",
      "Epoch: 102, Train Acc: 0.7229, Test Acc: 0.7375\n",
      "[104,     1] loss: 0.011\n",
      "Epoch: 103, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[105,     1] loss: 0.012\n",
      "Epoch: 104, Train Acc: 0.7222, Test Acc: 0.7375\n",
      "[106,     1] loss: 0.011\n",
      "Epoch: 105, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[107,     1] loss: 0.012\n",
      "Epoch: 106, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[108,     1] loss: 0.012\n",
      "Epoch: 107, Train Acc: 0.7228, Test Acc: 0.7375\n",
      "[109,     1] loss: 0.011\n",
      "Epoch: 108, Train Acc: 0.7228, Test Acc: 0.7375\n",
      "[110,     1] loss: 0.012\n",
      "Epoch: 109, Train Acc: 0.7221, Test Acc: 0.7367\n",
      "[111,     1] loss: 0.012\n",
      "Epoch: 110, Train Acc: 0.7225, Test Acc: 0.7380\n",
      "[112,     1] loss: 0.012\n",
      "Epoch: 111, Train Acc: 0.7227, Test Acc: 0.7375\n",
      "[113,     1] loss: 0.011\n",
      "Epoch: 112, Train Acc: 0.7227, Test Acc: 0.7380\n",
      "[114,     1] loss: 0.011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\traingnn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(loader\u001b[39m.\u001b[39mdataset)  \u001b[39m# Derive ratio of correct predictions.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m200\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=53'>54</a>\u001b[0m     train()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=55'>56</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m test(train_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=56'>57</a>\u001b[0m     test_acc \u001b[39m=\u001b[39m test(test_dataloader)\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\traingnn.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=12'>13</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):  \u001b[39m# Iterate in batches over the training dataset.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=15'>16</a>\u001b[0m     data\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mbatch\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mbatch\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=17'>18</a>\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39medge_attr,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000009?line=18'>19</a>\u001b[0m                 data\u001b[39m.\u001b[39mbatch)  \u001b[39m# Perform a single forward pass.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\traingnn.ipynb Cell 4'\u001b[0m in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000003?line=12'>13</a>\u001b[0m raw_data \u001b[39m=\u001b[39m read_record(current_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000003?line=13'>14</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39miloc[idx][\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000003?line=14'>15</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mbuild(raw_data, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/traingnn.ipynb#ch0000003?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\GraphBuilder\\graphbuilder.py:64\u001b[0m, in \u001b[0;36mMomentsAndPearson.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=62'>63</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mbuild(data, label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\GraphBuilder\\graphbuilder.py:21\u001b[0m, in \u001b[0;36mBaseGraphBuilder.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=18'>19</a>\u001b[0m \u001b[39m@abstractmethod\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=20'>21</a>\u001b[0m     node_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_feature_extractor\u001b[39m.\u001b[39;49mextract_features(data)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=21'>22</a>\u001b[0m     edge_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_feature_extractor\u001b[39m.\u001b[39mextract_features(data)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/graphbuilder.py?line=22'>23</a>\u001b[0m     format_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_label(label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src\\GraphBuilder\\node_extractors.py:49\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/node_extractors.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_features\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/node_extractors.py?line=47'>48</a>\u001b[0m     mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/node_extractors.py?line=48'>49</a>\u001b[0m     std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/node_extractors.py?line=49'>50</a>\u001b[0m     variance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvar(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src/GraphBuilder/node_extractors.py?line=50'>51</a>\u001b[0m     entropy \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mdifferential_entropy(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvar\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3757\u001b[0m, in \u001b[0;36mvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=3753'>3754</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=3754'>3755</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m var(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, ddof\u001b[39m=\u001b[39mddof, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=3756'>3757</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_var(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, ddof\u001b[39m=\u001b[39mddof,\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=3757'>3758</a>\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Envs\\tfm\\lib\\site-packages\\numpy\\core\\_methods.py:212\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=206'>207</a>\u001b[0m     dtype \u001b[39m=\u001b[39m mu\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mf8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=208'>209</a>\u001b[0m \u001b[39m# Compute the mean.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=209'>210</a>\u001b[0m \u001b[39m# Note that if dtype is not of inexact type then arraymean will\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=210'>211</a>\u001b[0m \u001b[39m# not be either.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=211'>212</a>\u001b[0m arrmean \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=212'>213</a>\u001b[0m \u001b[39m# The shape of rcount has to match arrmean to not change the shape of out\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=213'>214</a>\u001b[0m \u001b[39m# in broadcasting. Otherwise, it cannot be stored back to arrmean.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=214'>215</a>\u001b[0m \u001b[39mif\u001b[39;00m rcount\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/_methods.py?line=215'>216</a>\u001b[0m     \u001b[39m# fast-path for default case when where is True\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = EEGGNN(True, 64, 64)\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "model = model.double()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "total = 2756 + 6461 + 4430\n",
    "criterion = torch.nn.CrossEntropyLoss()#weight=torch.tensor([1 / (2756 / total), 1 / (6461 / total), 1 / (4430 / total)], dtype=torch.float64))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):  # Iterate in batches over the training dataset.\n",
    "\n",
    "        data.batch = data.batch.view(data.batch.shape[0], -1)\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.edge_attr,\n",
    "                    data.batch)  # Perform a single forward pass.\n",
    "\n",
    "        loss = criterion(out, torch.argmax(data.label, dim=1))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i%100 == 0:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        print(\"Prediction: \")\n",
    "        #print(\"Prediction shape:\" )\n",
    "        print(pred)\n",
    "        #print(pred.shape)\n",
    "        \n",
    "        print(\"Label: \")\n",
    "        #print(\"Label shape:\" )\n",
    "        print(data.label)\n",
    "        #print(data.label.shape)\n",
    "        \n",
    "        correct += int((pred == torch.argmax(data.label, dim=1)).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    train()\n",
    "    \n",
    "    train_acc = test(train_dataloader)\n",
    "    test_acc = test(test_dataloader)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    print(\n",
    "        f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 1, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 0, 2, 2, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(data.label, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49828187f4dc564a08cffdc3b9732e1c7952dfdfaa36f705d81755fe28017e2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('tfm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
